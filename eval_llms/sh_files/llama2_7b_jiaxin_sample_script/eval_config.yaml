General:
  dataset: "UniGeo" # 随便取 ["UniGeo" or other]
  model_type: "opensource_model" # [api_model, opensource_model] 如果从local load weights, 那就选"opensource_model"
  model_name: "/users/gvb20207/Code_weights/llama-2-13b-chat-hf" # 随便, 只要和你跑的模型能对上就行, "result"文件夹保存的predicitons的文件名会包含这个"model_name"
  eval_dataset_path: "datas/"    # 数据集的第一层文件夹位置, 是"relative directory path"
  input_file: "unigeo/UniGeo_CAL_test.json" # 测试集文件在"eval_dataset_path"的位置, 是"relative directory path", 例如这里, 文件存在主目录的"LLM_eval/dataset_merge/all.json"中
  input_parse_file: "unigeo/UniGeo_CAL_parse_test.json"
  output_dir: "result" # predictions存的文件夹, 是"relative dir path"
  weight_path: "/users/gvb20207/Code_weights/codellama2-13b-hf"   # 模型weights的地址, 是"absolute path"
  max_seq_length: 1024  # 生成的文本最长长度
  bsz: 1                # 测试默认batch为1, 如果设置其他数值, 肯定会出bug, 哈哈
  load_in_8bit: False   # 暂时没用
  from_local: True      # 是否从local load model weights
  merge_type: "naive"   # ["naive"] 怎么把 "diagram_description", "text", "choice_list"合成一个问题, 参考"GeoEval/tool/merge_key_val.py"
  prompt_type: "llama2" # ["llama2", "general", "easy", "choice"] 加不同的prompt, 参考"GeoEval/tool/prompt/llama2_prompt.py"
  sample_number: -1     # 用于debug, 测试多少数据集就停止并保存predictions, 设置为"-1"代表跑所有的数据集